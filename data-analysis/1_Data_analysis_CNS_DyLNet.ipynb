{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1a2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../code/\")\n",
    "from data_analysis import groups_at_time_t, group_size_dist\n",
    "from data_analysis import get_transition_matrix, transition_matrix_to_df\n",
    "from data_analysis import get_group_durations\n",
    "from data_analysis import get_group_times, get_dis_agg_matrices, get_full_dis_agg_matrices, dis_agg_matrix_to_df\n",
    "from data_analysis import get_group_similarity\n",
    "from data_analysis import measure_social_memory, get_interevent_times, get_node_trajectory\n",
    "from data_analysis import get_probs_leaving_group\n",
    "from utils import get_Hs_from_groups_dict, get_cumulative_Gs_from_Hs, reduce_number_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5990dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up directories for outputs\n",
    "DIRs_TO_CREATE = [\"results/CNS\", \"results/DyLNet\"]\n",
    "        \n",
    "for directory in DIRs_TO_CREATE:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53308a44",
   "metadata": {},
   "source": [
    "# 1. Extracting group interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64768768",
   "metadata": {},
   "source": [
    "### CNS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39f2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"CNS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "160c6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># timestamp</th>\n",
       "      <th>user_a</th>\n",
       "      <th>user_b</th>\n",
       "      <th>rssi</th>\n",
       "      <th>datetime</th>\n",
       "      <th>DoW</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # timestamp  user_a  user_b  rssi             datetime     DoW  hour\n",
       "0            0       0      -1     0  2013-03-03 00:00:00  Sunday     0\n",
       "1            0       1      -1     0  2013-03-03 00:00:00  Sunday     0\n",
       "2            0       2      -1     0  2013-03-03 00:00:00  Sunday     0\n",
       "3            0       5      -1     0  2013-03-03 00:00:00  Sunday     0\n",
       "4            0       6      -1     0  2013-03-03 00:00:00  Sunday     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-processed/%s/'%dataset\n",
    "\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "if not os.path.exists(OUT_PATH): os.makedirs(OUT_PATH)\n",
    "\n",
    "FNAME = \"%s_bluetooth_processed.csv.gz\"%dataset\n",
    "df = pd.read_csv(IN_PATH+FNAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb10375",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = ['in-class', 'out-of-class', 'weekend']\n",
    "\n",
    "#Selecting weekends\n",
    "weekends_timestamps = list(df[(df['DoW']=='Sunday')|(df['DoW']=='Saturday')]['# timestamp'].unique())\n",
    "#Selecting workweek days classtime\n",
    "workweek_class_timestamps = list(df[(df['DoW']!='Sunday')&(df['DoW']!='Saturday')&((df['hour']>=8)&(df['hour']<=17))]['# timestamp'].unique())\n",
    "#Selecting workweek days out of classtime\n",
    "workweek_noclass_timestamps = list(df[(df['DoW']!='Sunday')&(df['DoW']!='Saturday')&((df['hour']<8)|(df['hour']>17))]['# timestamp'].unique())\n",
    "\n",
    "context_timestamps = {'in-class': workweek_class_timestamps,\n",
    "                      'out-of-class': workweek_noclass_timestamps,\n",
    "                      'weekend': weekends_timestamps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d17b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-class\n",
      "out-of-class\n",
      "weekend\n"
     ]
    }
   ],
   "source": [
    "for context in contexts:\n",
    "    print(context)\n",
    "    dfx = df[df['# timestamp'].isin(context_timestamps[context])]\n",
    "    \n",
    "    groups_at_t_dict = {}\n",
    "    for timestamp in list(dfx['# timestamp'].unique()):\n",
    "        groups_at_t_dict[timestamp] = groups_at_time_t(dfx, timestamp, dataset=dataset)\n",
    "    \n",
    "    #Saving\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    pickle.dump(groups_at_t_dict, open(OUT_PATH+FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267db3f8",
   "metadata": {},
   "source": [
    "### DylNet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc96da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"DyLNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10648a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_a</th>\n",
       "      <th>user_b</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>morning-afternoon</th>\n",
       "      <th>context</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>in-class</td>\n",
       "      <td>2421540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>in-class</td>\n",
       "      <td>2421541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>in-class</td>\n",
       "      <td>2421542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>in-class</td>\n",
       "      <td>2421543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>in-class</td>\n",
       "      <td>2421544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_a  user_b  week  day morning-afternoon   context  timestamp\n",
       "0      45     140     1    1           morning  in-class    2421540\n",
       "1      45     140     1    1           morning  in-class    2421541\n",
       "2      45     140     1    1           morning  in-class    2421542\n",
       "3      45     140     1    1           morning  in-class    2421543\n",
       "4      45     140     1    1           morning  in-class    2421544"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-processed/%s/'%dataset\n",
    "\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "if not os.path.exists(OUT_PATH): os.makedirs(OUT_PATH)\n",
    "\n",
    "FNAME = \"%s_processed.csv.gz\"%dataset\n",
    "df = pd.read_csv(IN_PATH+FNAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb19917",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = ['in-class', 'out-of-class']\n",
    "\n",
    "for context in contexts:\n",
    "    print(context)\n",
    "    dfx = df[df['context']==context]\n",
    "    \n",
    "    groups_at_t_dict = {}\n",
    "    for timestamp in list(dfx['timestamp'].unique()):\n",
    "        groups_at_t_dict[timestamp] = groups_at_time_t(dfx, timestamp, dataset=dataset)\n",
    "        if timestamp%1000==0: print(timestamp)\n",
    "    \n",
    "    #Saving\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    pickle.dump(groups_at_t_dict, open(OUT_PATH+FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2e5f4",
   "metadata": {},
   "source": [
    "# 2. Analyses for main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43d460",
   "metadata": {},
   "source": [
    "## Computing group size distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024b1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b33ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS\n",
      "in-class\n",
      "out-of-class\n",
      "weekend\n",
      "DyLNet\n",
      "in-class\n",
      "out-of-class\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "\n",
    "        #Computing group dise distribution\n",
    "        ks, Pks = group_size_dist(groups_at_t_dict)\n",
    "\n",
    "        #Saving \n",
    "        gsize_df = pd.DataFrame({'k':ks,'Pk':Pks})\n",
    "        FNAME = \"Pk_%s.csv\"%context\n",
    "        gsize_df.to_csv(OUT_PATH+FNAME, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f644c",
   "metadata": {},
   "source": [
    "## Computing node transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4b852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc5357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS\n",
      "out-of-class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/data_analysis.py:76: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/data_analysis.py:76: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyLNet\n",
      "in-class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/data_analysis.py:76: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out-of-class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/data_analysis.py:76: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        #Converting to xgi object\n",
    "        Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "        #Computing transition matrix\n",
    "        T = get_transition_matrix(Hs, max_k = 20, normed=True)\n",
    "        #Converting it to a dataframe\n",
    "        df_T = transition_matrix_to_df(T)\n",
    "        #Saving\n",
    "        OUT_FNAME = \"T_%s.csv\"%context\n",
    "        df_T.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab1434",
   "metadata": {},
   "source": [
    "## Computing group duration distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f08137",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631283b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS\n",
      "in-class\n",
      "out-of-class\n",
      "weekend\n",
      "DyLNet\n",
      "in-class\n",
      "out-of-class\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        #Computing group durations\n",
    "        durations = get_group_durations(groups_at_t_dict)\n",
    "        #Saving\n",
    "        OUT_FNAME = \"gdurations_%s.p\"%context\n",
    "        pickle.dump( durations, open( OUT_PATH+OUT_FNAME, \"wb\" ) )            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfed47",
   "metadata": {},
   "source": [
    "## Computing group disaggregation and aggregation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb7f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1992a1",
   "metadata": {},
   "source": [
    "First of all, I compute group times, that is for each group I save info on members and times of group creation and destruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7d1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyLNet\n",
      "in-class\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed. Saving...\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        print(\"Read. Computing groups and time...\")\n",
    "        #Computing times of groups start and end\n",
    "        groups_and_times = get_group_times(groups_at_t_dict)\n",
    "        print(\"Groups and times computed. Saving...\")\n",
    "        #Saving\n",
    "        OUT_FNAME = \"group_times_%s.p\"%context\n",
    "        pickle.dump(groups_and_times, open(OUT_PATH+OUT_FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d35e8e",
   "metadata": {},
   "source": [
    "### 1. Matrices using only size of biggest sub-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce916dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyLNet\n",
      "in-class\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/data_analysis.py:280: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saving...\n",
      "out-of-class\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed.\n",
      "Done. Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/data_analysis.py:280: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading times of groups start and end\n",
    "        FNAME = \"group_times_%s.p\"%context\n",
    "        groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        print(\"Groups read. Computing matrices...\")\n",
    "        #Computing dis- and aggregation matrices \n",
    "        D, A = get_dis_agg_matrices(groups_at_t_dict, groups_and_times, max_k = 21, normed=True)\n",
    "        #Converting them to dataframes\n",
    "        df_D = dis_agg_matrix_to_df(D)\n",
    "        df_A = dis_agg_matrix_to_df(A)\n",
    "        print(\"Done. Saving...\")\n",
    "        #Saving\n",
    "        OUT_FNAME = \"D_%s.csv\"%context\n",
    "        df_D.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)   \n",
    "        OUT_FNAME = \"A_%s.csv\"%context\n",
    "        df_A.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802583f",
   "metadata": {},
   "source": [
    "### 2. Matrices using sizes of all sub-groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6935c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6553aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyLNet\n",
      "in-class\n",
      "Groups read. Computing matrices...\n",
      "Done. Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  row_sums = matrix.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading times of groups start and end\n",
    "        FNAME = \"group_times_%s.p\"%context\n",
    "        groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        print(\"Groups read. Computing matrices...\")\n",
    "        #Computing dis- and aggregation matrices \n",
    "        D, A = get_full_dis_agg_matrices(groups_at_t_dict, groups_and_times, max_k = 21, normed=True)\n",
    "        #Converting them to dataframes\n",
    "        df_D = dis_agg_matrix_to_df(D)\n",
    "        df_A = dis_agg_matrix_to_df(A)\n",
    "        print(\"Done. Saving...\")\n",
    "        #Saving\n",
    "        OUT_FNAME = \"Dfull_%s.csv\"%context\n",
    "        df_D.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)   \n",
    "        OUT_FNAME = \"Afull_%s.csv\"%context\n",
    "        df_A.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc8c02",
   "metadata": {},
   "source": [
    "# 3. Analyses for SI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa576eea",
   "metadata": {},
   "source": [
    "## Computing group similarity at consecutive times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc442cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb94325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS\n",
      "in-class\n",
      "Ready. Computing Jaccard...\n",
      "Done. Saving...\n",
      "out-of-class\n",
      "Ready. Computing Jaccard...\n",
      "Done. Saving...\n",
      "weekend\n",
      "Ready. Computing Jaccard...\n",
      "Done. Saving...\n",
      "DyLNet\n",
      "in-class\n",
      "Ready. Computing Jaccard...\n",
      "Done. Saving...\n",
      "out-of-class\n",
      "Ready. Computing Jaccard...\n",
      "Done. Saving...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        #Converting to xgi object\n",
    "        Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "        print(\"Ready. Computing Jaccard...\")\n",
    "        #Extracting group similarity\n",
    "        J = get_group_similarity(Hs)\n",
    "        print(\"Done. Saving...\")\n",
    "        #Dumping full results\n",
    "        OUT_FNAME = \"Jfull_%s.p\"%context\n",
    "        file = open(OUT_PATH+OUT_FNAME, 'wb')\n",
    "        pickle.dump(J, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75481f53",
   "metadata": {},
   "source": [
    "## Checking multiple membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14418a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87f12fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_count_collection = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    \n",
    "    deg_count_collection[dataset] = {}\n",
    "    for context in contexts[dataset]:    \n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "\n",
    "        Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "        \n",
    "        #I store here the degree of all nodes at all times\n",
    "        flatten_degrees = []\n",
    "\n",
    "        for t, H in Hs.items():\n",
    "            for n, k in H.degree().items():\n",
    "                flatten_degrees.append(k)\n",
    "\n",
    "        #Degree count\n",
    "        deg_count = Counter(flatten_degrees)\n",
    "        \n",
    "        deg_count_collection[dataset][context] = deg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e473f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS in-class 0.7490856257302895\n",
      "CNS out-of-class 0.9613489263179696\n",
      "CNS weekend 0.9758061337549213\n",
      "DyLNet in-class 0.8038052734285681\n",
      "DyLNet out-of-class 0.9413629864445646\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(datasets):\n",
    "    for context in contexts[dataset]:\n",
    "        dc = OrderedDict(deg_count_collection[dataset][context].most_common())\n",
    "        print(dataset, context, dc[1]/sum(dc.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac89108",
   "metadata": {},
   "source": [
    "## Measuring social memory\n",
    "I want to measure the density of known nodes in the group each node is chosing (when changing) compared to a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798002b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        #Converting to xgi object\n",
    "        Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "        print(\"Hypergraphs read.\")\n",
    "        #Reading times of groups start and end\n",
    "        FNAME = \"group_times_%s.p\"%context\n",
    "        groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        print(\"Groups and times read.\")\n",
    "        #Computing the cumulative networks of contacts\n",
    "        Gs = get_cumulative_Gs_from_Hs(Hs)\n",
    "        print(\"Cumulative contact graphs computed.\")\n",
    "        #Measuring 'social memory' dataframe\n",
    "        memory_df = measure_social_memory(Hs, groups_at_t_dict, Gs, groups_and_times)\n",
    "        print(\"Social memory dataframe computed. Saving...\")\n",
    "        #Saving\n",
    "        OUT_FNAME = \"social_memory_%s.csv.gz\"%context\n",
    "        memory_df.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False, compression=\"gzip\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d1594",
   "metadata": {},
   "source": [
    "## Measuring inter-event time distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760418ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading times of groups start and end\n",
    "        FNAME = \"group_times_%s.p\"%context\n",
    "        groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        print(\"Groups and times read.\")\n",
    "        interevent_times = get_interevent_times(groups_and_times)\n",
    "        print(\"Interevent times computed. Saving...\")\n",
    "        #Saving\n",
    "        OUT_FNAME = \"interevent_times_%s.p\"%context\n",
    "        pickle.dump( interevent_times, open( OUT_PATH+OUT_FNAME, \"wb\" ) )            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25798f16",
   "metadata": {},
   "source": [
    "## Trajectory across group sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a214667",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f13c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    for context in contexts[dataset]:    \n",
    "        print(context)\n",
    "        #Reading\n",
    "        FNAME = \"groups_at_t_%s.p\"%context\n",
    "        groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "        #Converting to xgi object\n",
    "        Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "        print(\"Hypergraphs read.\")\n",
    "        Traj, index_to_node = get_node_trajectory(Hs)\n",
    "        print(\"Trajectory matrix computed.\")\n",
    "        #Saving\n",
    "        OUT_FNAME = \"trajectories_matrix_%s.p\"%context\n",
    "        pickle.dump( Traj, open( OUT_PATH+OUT_FNAME, \"wb\" ) )   \n",
    "        OUT_FNAME = \"trajectories_matrix_i2n%s.p\"%context\n",
    "        pickle.dump( index_to_node, open( OUT_PATH+OUT_FNAME, \"wb\" ) )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122fbc3",
   "metadata": {},
   "source": [
    "## Computing the probabilities of leaving groups (to inform our Logistic function)\n",
    "I need to compute the probability $p_n$ that a node leaves a group of size $k$ after a residence time there of $\\tau$ timesteps. I will thus have a number of $p_k(\\tau)$ curves for different $k$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc9a2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"CNS\", \"DyLNet\"]\n",
    "contexts = {\"CNS\": ['in-class', 'out-of-class', 'weekend'],\n",
    "            \"DyLNet\": ['in-class', 'out-of-class']}\n",
    "\n",
    "taus=np.arange(1,1000)\n",
    "gsizes = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b1d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNS\n",
      "in-class\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "out-of-class\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "weekend\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "DyLNet\n",
      "in-class\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "out-of-class\n",
      "Computing probabilities...\n",
      "Done. Saving...\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    \n",
    "    for context in contexts[dataset]:\n",
    "        print(context)\n",
    "        #Input\n",
    "        IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "        #Output\n",
    "        OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "        #Loading group_duration\n",
    "        IN_FNAME = 'gdurations_%s.p'%context\n",
    "        durations = pickle.load(open(IN_PATH+IN_FNAME, \"rb\" ) )\n",
    "        print(\"Computing probabilities...\")\n",
    "        prob_by_size = get_probs_leaving_group(durations, gsizes, taus)\n",
    "        print(\"Done. Saving...\")\n",
    "        OUT_FNAME = \"Prob_leaving_group_sizek_after_tau_%s.p\"%context\n",
    "        pickle.dump(prob_by_size, open(OUT_PATH+OUT_FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a968b",
   "metadata": {},
   "source": [
    "I will aggregate the results (ready to plot) that will form part of Figure 4 of the main text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6634067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['CNS','DyLNet']\n",
    "context = 'out-of-class'\n",
    "\n",
    "for dataset in datasets:\n",
    "    IN_PATH = \"results/%s/\"%dataset\n",
    "    IN_FNAME = \"Prob_leaving_group_sizek_after_tau_%s.p\"%context\n",
    "\n",
    "    OUT_PATH = \"results/%s/\"%dataset\n",
    "    OUT_FNAME = \"A_Binned_group_change_prob_%s.p\"%context\n",
    "\n",
    "    #Reading the probabilities I just computed\n",
    "    prob = pickle.load(open(IN_PATH+IN_FNAME, \"rb\" ) )\n",
    "\n",
    "    ks=[1,2,3,4]\n",
    "\n",
    "    x_data=list(np.arange(1,1000))*len(ks)\n",
    "    y_data=[]\n",
    "\n",
    "    for i, k in enumerate(ks):\n",
    "        ############## DATA\n",
    "        y_temp = prob[k]\n",
    "        y_data = y_data+y_temp\n",
    "\n",
    "    #Binning\n",
    "    xx_data, yy_data = reduce_number_of_points(x_data, y_data, bins=np.logspace(0,3,30))\n",
    "    #Converting 0s to nans to avoid vertical lines\n",
    "    yy_data[yy_data == 0] = np.nan\n",
    "    #Removing nans before fitting\n",
    "    valid = ~(np.isnan(xx_data) | np.isnan(yy_data))\n",
    "\n",
    "    #Saving\n",
    "    pickle.dump((xx_data[valid], yy_data[valid]), open(OUT_PATH+OUT_FNAME, \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
