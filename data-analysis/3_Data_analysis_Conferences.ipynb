{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b59f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../code/\")\n",
    "from data_analysis import groups_at_time_t, group_size_dist\n",
    "from data_analysis import get_transition_matrix, transition_matrix_to_df\n",
    "from data_analysis import get_group_durations\n",
    "from data_analysis import get_group_times, get_dis_agg_matrices, get_full_dis_agg_matrices, dis_agg_matrix_to_df\n",
    "from data_analysis import get_group_similarity\n",
    "from data_analysis import measure_social_memory, get_interevent_times, get_node_trajectory\n",
    "from data_analysis import get_probs_leaving_group\n",
    "from utils import get_Hs_from_groups_dict, get_cumulative_Gs_from_Hs, reduce_number_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450f9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up directories for outputs\n",
    "DIRs_TO_CREATE = [\"results/Confs\"]\n",
    "        \n",
    "for directory in DIRs_TO_CREATE:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c742b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Confs\"\n",
    "contexts = [\"conf16\", \"conf17\", \"conf18\", \"conf19\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e87d4c",
   "metadata": {},
   "source": [
    "## Extracting group interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34876b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "conf17\n",
      "conf18\n",
      "conf19\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-processed/%s/'%dataset\n",
    "\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "if not os.path.exists(OUT_PATH): os.makedirs(OUT_PATH)\n",
    "    \n",
    "for context in contexts:\n",
    "    print(context)\n",
    "\n",
    "    IN_FNAME = \"%s_processed.csv.gz\"%context\n",
    "    df = pd.read_csv(IN_PATH+IN_FNAME)\n",
    "    \n",
    "    groups_at_t_dict = {}\n",
    "    for timestamp in list(df['timestamp'].unique()):\n",
    "        groups_at_t_dict[timestamp] = groups_at_time_t(df, timestamp, dataset=dataset)\n",
    "    \n",
    "    #Saving\n",
    "    OUT_FNAME = \"groups_at_t_%s.p\"%context\n",
    "    pickle.dump(groups_at_t_dict, open(OUT_PATH+OUT_FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c5f8d",
   "metadata": {},
   "source": [
    "## Computing group size distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283b37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "conf17\n",
      "conf18\n",
      "conf19\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "if not os.path.exists(OUT_PATH): os.makedirs(OUT_PATH)\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "\n",
    "    #Computing group dise distribution\n",
    "    ks, Pks = group_size_dist(groups_at_t_dict)\n",
    "\n",
    "    #Saving \n",
    "    gsize_df = pd.DataFrame({'k':ks,'Pk':Pks})\n",
    "    FNAME = \"Pk_%s.csv\"%context\n",
    "    gsize_df.to_csv(OUT_PATH+FNAME, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71556f7c",
   "metadata": {},
   "source": [
    "## Transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5769078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:156: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:156: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:156: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:156: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    #Converting to xgi object\n",
    "    Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "    #Computing transition matrix\n",
    "    T = get_transition_matrix(Hs, max_k = 20, normed=True)\n",
    "    #Converting it to a dataframe\n",
    "    df_T = transition_matrix_to_df(T)\n",
    "    #Saving\n",
    "    OUT_FNAME = \"T_%s.csv\"%context\n",
    "    df_T.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce1f40",
   "metadata": {},
   "source": [
    "## Group duration distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c46c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "conf17\n",
      "conf18\n",
      "conf19\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    #Computing group durations\n",
    "    durations = get_group_durations(groups_at_t_dict)\n",
    "    #Saving\n",
    "    OUT_FNAME = \"gdurations_%s.p\"%context\n",
    "    pickle.dump( durations, open( OUT_PATH+OUT_FNAME, \"wb\" ) )            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949661f1",
   "metadata": {},
   "source": [
    "## Group aggregation and disaggregation matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f58c1",
   "metadata": {},
   "source": [
    "First of all, I compute group times, that is for each group I save info on members and times of group creation and destruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2a50e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed. Saving...\n",
      "conf17\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed. Saving...\n",
      "conf18\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed. Saving...\n",
      "conf19\n",
      "Read. Computing groups and time...\n",
      "Groups and times computed. Saving...\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    print(\"Read. Computing groups and time...\")\n",
    "    #Computing times of groups start and end\n",
    "    groups_and_times = get_group_times(groups_at_t_dict)\n",
    "    print(\"Groups and times computed. Saving...\")\n",
    "    #Saving\n",
    "    OUT_FNAME = \"group_times_%s.p\"%context\n",
    "    pickle.dump(groups_and_times, open(OUT_PATH+OUT_FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e95cff",
   "metadata": {},
   "source": [
    "Computing matrices associated to size of the biggest sub-group joining/leaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a17cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "Groups read. Computing matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saving...\n",
      "conf17\n",
      "Groups read. Computing matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saving...\n",
      "conf18\n",
      "Groups read. Computing matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saving...\n",
      "conf19\n",
      "Groups read. Computing matrices...\n",
      "Done. Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iacopoiacopini/Local_files/Marton/temporal-group-interactions/data-analysis/../code/utils.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_matrix = matrix / row_sums[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading groups and times\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    #Reading times of groups start and end\n",
    "    FNAME = \"group_times_%s.p\"%context\n",
    "    groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    print(\"Groups read. Computing matrices...\")\n",
    "    #Computing dis- and aggregation matrices \n",
    "    D, A = get_dis_agg_matrices(groups_at_t_dict, groups_and_times, max_k = 15, normed=True)\n",
    "    #Converting them to dataframes\n",
    "    df_D = dis_agg_matrix_to_df(D)\n",
    "    df_A = dis_agg_matrix_to_df(A)\n",
    "    print(\"Done. Saving...\")\n",
    "    #Saving\n",
    "    OUT_FNAME = \"D_%s.csv\"%context\n",
    "    df_D.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)   \n",
    "    OUT_FNAME = \"A_%s.csv\"%context\n",
    "    df_A.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b046e9b8",
   "metadata": {},
   "source": [
    "## Checking multi-membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a458d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "deg_count_collection = {}\n",
    "    \n",
    "for context in contexts:    \n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "\n",
    "    Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "\n",
    "    #I store here the degree of all nodes at all times\n",
    "    flatten_degrees = []\n",
    "\n",
    "    for t, H in Hs.items():\n",
    "        for n, k in H.degree().items():\n",
    "            flatten_degrees.append(k)\n",
    "\n",
    "    #Degree count\n",
    "    deg_count = Counter(flatten_degrees)\n",
    "    deg_count_collection[context] = deg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8001cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16 0.6124441051368742\n",
      "conf17 0.7598521979448185\n",
      "conf18 0.7018039980497318\n",
      "conf19 0.7751829826166514\n"
     ]
    }
   ],
   "source": [
    "for context in contexts:\n",
    "    dc = OrderedDict(deg_count_collection[context].most_common())\n",
    "    print(context, dc[1]/sum(dc.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f3bc92",
   "metadata": {},
   "source": [
    "## Measuring social memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc306a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "Hypergraphs read.\n",
      "Groups and times read.\n",
      "Cumulative contact graphs computed.\n",
      "Social memory dataframe computed. Saving...\n",
      "conf17\n",
      "Hypergraphs read.\n",
      "Groups and times read.\n",
      "Cumulative contact graphs computed.\n",
      "Social memory dataframe computed. Saving...\n",
      "conf18\n",
      "Hypergraphs read.\n",
      "Groups and times read.\n",
      "Cumulative contact graphs computed.\n",
      "Social memory dataframe computed. Saving...\n",
      "conf19\n",
      "Hypergraphs read.\n",
      "Groups and times read.\n",
      "Cumulative contact graphs computed.\n",
      "Social memory dataframe computed. Saving...\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    #Converting to xgi object\n",
    "    Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "    print(\"Hypergraphs read.\")\n",
    "    #Reading times of groups start and end\n",
    "    FNAME = \"group_times_%s.p\"%context\n",
    "    groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    print(\"Groups and times read.\")\n",
    "    #Computing the cumulative networks of contacts\n",
    "    Gs = get_cumulative_Gs_from_Hs(Hs)\n",
    "    print(\"Cumulative contact graphs computed.\")\n",
    "    #Measuring 'social memory' dataframe\n",
    "    memory_df = measure_social_memory(Hs, groups_at_t_dict, Gs, groups_and_times)\n",
    "    print(\"Social memory dataframe computed. Saving...\")\n",
    "    #Saving\n",
    "    OUT_FNAME = \"social_memory_%s.csv.gz\"%context\n",
    "    memory_df.to_csv(OUT_PATH+OUT_FNAME, header=True, index=False, compression=\"gzip\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72329483",
   "metadata": {},
   "source": [
    "## Computing inter-event times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307d64c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "Groups and times read.\n",
      "Interevent times computed. Saving...\n",
      "conf17\n",
      "Groups and times read.\n",
      "Interevent times computed. Saving...\n",
      "conf18\n",
      "Groups and times read.\n",
      "Interevent times computed. Saving...\n",
      "conf19\n",
      "Groups and times read.\n",
      "Interevent times computed. Saving...\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading times of groups start and end\n",
    "    FNAME = \"group_times_%s.p\"%context\n",
    "    groups_and_times = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    print(\"Groups and times read.\")\n",
    "    interevent_times = get_interevent_times(groups_and_times)\n",
    "    print(\"Interevent times computed. Saving...\")\n",
    "    #Saving\n",
    "    OUT_FNAME = \"interevent_times_%s.p\"%context\n",
    "    pickle.dump( interevent_times, open( OUT_PATH+OUT_FNAME, \"wb\" ) )            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac26a6b",
   "metadata": {},
   "source": [
    "## Computing trajectories across group sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0addcc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "Hypergraphs read.\n",
      "Trajectory matrix computed.\n",
      "conf17\n",
      "Hypergraphs read.\n",
      "Trajectory matrix computed.\n",
      "conf18\n",
      "Hypergraphs read.\n",
      "Trajectory matrix computed.\n",
      "conf19\n",
      "Hypergraphs read.\n",
      "Trajectory matrix computed.\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "#Output\n",
    "OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "for context in contexts:    \n",
    "    print(context)\n",
    "    #Reading\n",
    "    FNAME = \"groups_at_t_%s.p\"%context\n",
    "    groups_at_t_dict = pickle.load(open(IN_PATH+FNAME, \"rb\" ) )\n",
    "    #Converting to xgi object\n",
    "    Hs = get_Hs_from_groups_dict(groups_at_t_dict)\n",
    "    print(\"Hypergraphs read.\")\n",
    "    Traj, index_to_node = get_node_trajectory(Hs)\n",
    "    print(\"Trajectory matrix computed.\")\n",
    "    #Saving\n",
    "    OUT_FNAME = \"trajectories_matrix_%s.p\"%context\n",
    "    pickle.dump( Traj, open( OUT_PATH+OUT_FNAME, \"wb\" ) )   \n",
    "    OUT_FNAME = \"trajectories_matrix_i2n%s.p\"%context\n",
    "    pickle.dump( index_to_node, open( OUT_PATH+OUT_FNAME, \"wb\" ) )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d56c0f",
   "metadata": {},
   "source": [
    "## Computing the probabilities of leaving groups (to inform our Logistic function)\n",
    "I need to compute the probability $p_n$ that a node leaves a group of size $k$ after a residence time there of $\\tau$ timesteps. I will thus have a number of $p_k(\\tau)$ curves for different $k$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d63840",
   "metadata": {},
   "outputs": [],
   "source": [
    "taus=np.arange(1,1000)\n",
    "gsizes = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72533edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf16\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "conf17\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "conf18\n",
      "Computing probabilities...\n",
      "Done. Saving...\n",
      "conf19\n",
      "Computing probabilities...\n",
      "Done. Saving...\n"
     ]
    }
   ],
   "source": [
    "for context in contexts:\n",
    "    print(context)\n",
    "    #Input\n",
    "    IN_PATH = '../data-analysis/results/%s/'%dataset\n",
    "    #Output\n",
    "    OUT_PATH = '../data-analysis/results/%s/'%dataset\n",
    "\n",
    "    #Loading group_duration\n",
    "    IN_FNAME = 'gdurations_%s.p'%context\n",
    "    durations = pickle.load(open(IN_PATH+IN_FNAME, \"rb\" ) )\n",
    "    print(\"Computing probabilities...\")\n",
    "    prob_by_size = get_probs_leaving_group(durations, gsizes, taus)\n",
    "    print(\"Done. Saving...\")\n",
    "    OUT_FNAME = \"Prob_leaving_group_sizek_after_tau_%s.p\"%context\n",
    "    pickle.dump(prob_by_size, open(OUT_PATH+OUT_FNAME, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7287dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
